{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad77d250",
   "metadata": {
    "papermill": {
     "duration": 0.018505,
     "end_time": "2021-06-07T00:09:44.379517",
     "exception": false,
     "start_time": "2021-06-07T00:09:44.361012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Customer Churn Prediction with Autogluon using Script mode\n",
    "_**이동통신 고객 이탈감지를 위해 Gradient Boosted Trees 사용하기**_\n",
    "\n",
    "소스 : https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Background](#Background)\n",
    "1. [Setup](#Setup)\n",
    "1. [Data](#Data)\n",
    "1. [Train](#Train)\n",
    "1. [Compile](#Compile)\n",
    "1. [Host](#Host)\n",
    "  1. [Evaluate](#Evaluate)\n",
    "  1. [Relative cost of errors](#Relative-cost-of-errors)\n",
    "1. [Extensions](#Extensions)\n",
    "\n",
    "---\n",
    "\n",
    "## Background\n",
    "\n",
    "_본 노트북의 내용은 다음 블로그에서도 확인할 수 있습니다. [AWS blog post](https://aws.amazon.com/blogs/ai/predicting-customer-churn-with-amazon-machine-learning/)_\n",
    "\n",
    "어떤 비즈니스이건 고객을 잃는 것은 손해로 연결됩니다. 불만족스러운 고객을 조기에 감지할 수 있다면 여러분은 그들에게 인센티브를 제공함으로써 보다 더 오래 머물도록 할 기회를 줄 것입니다. 본 노트북은 고객 이탈 예측(Churn Prediction)으로 잘 알려진, 불만족스러운 고객을 사전에 식별하는 유즈케이스를 머신러닝을 이용하여 자동으로 해결하고자 합니다. 머신러닝 모델은 완벽하게 예측하지는 못할 것입니다. 본 노트북은 이런 경우 어떻게 예측이 빗나간 케이스에 대하여 관련된 비용을 수용하는지까지 다룰 것입니다.\n",
    "\n",
    "고객 이탈 예측 예제에서 우리에게 익숙한 이동통신사 예를 사용할 것입니다. 서비스제공자는 고객이 탈퇴할 생각임을 알게 되면 적절한 타이밍에 인센티브를 제공할 수 있습니다. 전화기를 업그레이드하거나 새로운 기능을 활성화하여 계속 서비스를 사용하도록 합니다. 인센티브는 고객을 잃고 다시 확보하는 것보다 훨씬 비용 효율적인 경우가 많습니다. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "_본 노트북은 ml.m4.xlarge Sagemaker 노트북에서 생성하고 테스트되었습니다._\n",
    "\n",
    "다음 설정을 시작합니다.\n",
    "- 학습과 모델 데이터 저장에 사용할 S3 버켓과 prefix를 선언합니다. SageMaker 노트북 인스턴스와 동일한 리전에 위치해야 합니다.\n",
    "- 학습과 호스팅 작업에서 데이터에 엑서스할 때 사용할 IAM 역할(role)을 결정합니다. 역할의 생성은 aws 개발자문서를 참고하십시오. 만약 노트북인스턴스, 학습, 호스팅을 위해 하나 여러개의 별도 역할이 필요하다면 boto 정규식으로 표현된 IAM 풀네임 스트링을 사용합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3502722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.ag_model import (\n",
    "    AutoGluonTraining,\n",
    "    AutoGluonInferenceModel,\n",
    "    AutoGluonTabularPredictor,\n",
    ")\n",
    "from sagemaker import utils\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import os\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "output_path = f\"s3://{bucket}/{s3_prefix}/output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b2d2f8",
   "metadata": {
    "papermill": {
     "duration": 0.017739,
     "end_time": "2021-06-07T00:09:45.683322",
     "exception": false,
     "start_time": "2021-06-07T00:09:45.665583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "필요한 파이썬 라이브러리를 import 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31573db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T00:09:45.723197Z",
     "iopub.status.busy": "2021-06-07T00:09:45.722450Z",
     "iopub.status.idle": "2021-06-07T00:09:46.367234Z",
     "shell.execute_reply": "2021-06-07T00:09:46.366826Z"
    },
    "papermill": {
     "duration": 0.666347,
     "end_time": "2021-06-07T00:09:46.367361",
     "exception": false,
     "start_time": "2021-06-07T00:09:45.701014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e745c",
   "metadata": {
    "papermill": {
     "duration": 0.021555,
     "end_time": "2021-06-07T00:09:46.406743",
     "exception": false,
     "start_time": "2021-06-07T00:09:46.385188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Data\n",
    "\n",
    "이동 통신사에는 어떤 고객이 이탈하고 어떤 고객이 서비스를 계속 사용했는지에 대한 기록이 있습니다. 이 기록 정보를 이용하여 한 이동 통신사의 이탈에 대한 ML 모델을 구성하기 위해 모델을 학습할  할 수 있습니다. 모델을 학습 한 후 다른 임의 고객의 프로필 정보 (모델 학습에 사용한 것과 동일한 프로필 정보)를 모델에 전달하고 모델이이 고객이 이탈할지 여부를 예측하도록 할 수 있습니다. 물론 우리는 모델이 실수를 할 것으로 예상합니다. 결국 미래를 예측하는 것은 어려운 일입니다! 하지만 예측 오류를 처리하는 방법도 보여 드리겠습니다.\n",
    "\n",
    "우리가 사용하는 데이터 세트는 Daniel T. Larose의 책 [Discovering Knowledge in Data] (https://www.amazon.com/dp/0470908742/) 과 University of California Irvine Repository of Machine Learning Datasets에 언급되고 공개되었습니다. 이제 해당 데이터 세트를 다운로드하고 읽어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf6a982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_data validation_data test_data predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a9161d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T00:10:15.086298Z",
     "iopub.status.busy": "2021-06-07T00:10:15.085825Z",
     "iopub.status.idle": "2021-06-07T00:10:15.817444Z",
     "shell.execute_reply": "2021-06-07T00:10:15.817816Z"
    },
    "papermill": {
     "duration": 0.79455,
     "end_time": "2021-06-07T00:10:15.817950",
     "exception": false,
     "start_time": "2021-06-07T00:10:15.023400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of |class variable: \n",
      " count    500.000000\n",
      "mean       0.510000\n",
      "std        0.500401\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n",
      "Name: Churn?_True., dtype: float64\n"
     ]
    }
   ],
   "source": [
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "\n",
    "label = 'Churn?_True.'\n",
    "print(\"Summary of |class variable: \\n\", train_data[label].describe())\n",
    "\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f73f461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_header.csv\", header=True, index=False)\n",
    "validation_data.to_csv(\"validation_header.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090f7a0",
   "metadata": {
    "papermill": {
     "duration": 0.050157,
     "end_time": "2021-06-07T00:10:15.918579",
     "exception": false,
     "start_time": "2021-06-07T00:10:15.868422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Users can create their own training/inference scripts using [SageMaker Python SDK examples](https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script).\n",
    "The scripts we created allow to pass AutoGluon configuration as a YAML file (located in `data/config` directory).\n",
    "\n",
    "We are using [official AutoGluon Deep Learning Container images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) with custom training scripts (see `scripts/` directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fafa8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AutoGluonTraining(\n",
    "    role=role,\n",
    "    entry_point=\"scripts/tabular_train.py\",\n",
    "    region=region,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"0.3.1\",\n",
    "    base_job_name=\"autogluon-tabular-train\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57f209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "train_input = ag.sagemaker_session.upload_data(\n",
    "    path=\"train_header.csv\", key_prefix=s3_prefix\n",
    ")\n",
    "eval_input = ag.sagemaker_session.upload_data(\n",
    "    path=\"validation_header.csv\", key_prefix=s3_prefix\n",
    ")\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-med.yaml\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2e1c6",
   "metadata": {},
   "source": [
    "### Fit The Model\n",
    "For local training set `instance_type` to local.\n",
    "\n",
    "For non-local training the recommended instance type is `ml.m5.2xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed89ae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 14:05:44 Starting - Starting the training job...\n",
      "2021-12-05 14:06:07 Starting - Launching requested ML instancesProfilerReport-1638713143: InProgress\n",
      "......\n",
      "2021-12-05 14:07:07 Starting - Preparing the instances for training......\n",
      "2021-12-05 14:08:14 Downloading - Downloading input data...\n",
      "2021-12-05 14:08:27 Training - Downloading the training image..\u001b[34m2021-12-05 14:08:56,791 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2021-12-05 14:08:56,793 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-05 14:08:56,803 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{}', 'SM_USER_ENTRY_POINT': 'tabular_train.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"config\",\"test\",\"train\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'tabular_train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '8', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"test-autogluon-image-1638713143-b199\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/source/sourcedir.tar.gz\",\"module_name\":\"tabular_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tabular_train.py\"}', 'SM_USER_ARGS': '[]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TEST': '/opt/ml/input/data/test', 'SM_CHANNEL_CONFIG': '/opt/ml/input/data/config', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train'}\u001b[0m\n",
      "\u001b[34m2021-12-05 14:08:57,205 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-05 14:09:00,228 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-05 14:09:00,240 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-12-05 14:09:00,250 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"test-autogluon-image-1638713143-b199\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tabular_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tabular_train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=tabular_train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=tabular_train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"test-autogluon-image-1638713143-b199\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/source/sourcedir.tar.gz\",\"module_name\":\"tabular_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tabular_train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 tabular_train.py\u001b[0m\n",
      "\n",
      "2021-12-05 14:09:07 Training - Training image download completed. Training in progress.\u001b[34mStarting AG\u001b[0m\n",
      "\u001b[34mArgs: Namespace(ag_config='/opt/ml/input/data/config', model_dir='/opt/ml/model', n_gpus='0', output_data_dir='/opt/ml/output/data', test_dir='/opt/ml/input/data/test', training_dir='/opt/ml/input/data/train')\u001b[0m\n",
      "\u001b[34mUsing config-med.yaml\u001b[0m\n",
      "\u001b[34mRunning training job with the config:\u001b[0m\n",
      "\u001b[34m{'ag_fit_args': {'hyperparameters': None,\n",
      "                 'num_bag_folds': 2,\n",
      "                 'num_bag_sets': 1,\n",
      "                 'num_stack_levels': 0,\n",
      "                 'presets': 'medium_quality_faster_train'},\n",
      " 'ag_predictor_args': {'eval_metric': 'roc_auc', 'label': 'Churn?_True.'},\n",
      " 'feature_importance': True,\n",
      " 'leaderboard': True,\n",
      " 'num_gpus': 0,\n",
      " 'output_prediction_format': 'csv'}\u001b[0m\n",
      "\u001b[34mUsing train_header.csv\u001b[0m\n",
      "\u001b[34mWarning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\u001b[0m\n",
      "\u001b[34mPresets specified: ['medium_quality_faster_train']\u001b[0m\n",
      "\u001b[34mBeginning AutoGluon training ...\u001b[0m\n",
      "\u001b[34mAutoGluon will save models to \"/opt/ml/model/\"\u001b[0m\n",
      "\u001b[34mAutoGluon Version:  0.3.1\u001b[0m\n",
      "\u001b[34mTrain Data Rows:    500\u001b[0m\n",
      "\u001b[34mTrain Data Columns: 99\u001b[0m\n",
      "\u001b[34mPreprocessing data ...\u001b[0m\n",
      "\u001b[34mAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\u001b[0m\n",
      "\u001b[34m#0112 unique label values:  [0, 1]\u001b[0m\n",
      "\u001b[34m#011If 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\u001b[0m\n",
      "\u001b[34mSelected class <--> label mapping:  class 1 = 1, class 0 = 0\u001b[0m\n",
      "\u001b[34mUsing Feature Generators to preprocess the data ...\u001b[0m\n",
      "\u001b[34mFitting AutoMLPipelineFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Available Memory:                    31124.55 MB\u001b[0m\n",
      "\u001b[34m#011Train Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34m#011Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\u001b[0m\n",
      "\u001b[34m#011Stage 1 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting AsTypeFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011#011#011Note: Converting 88 features to boolean dtype as they only contain 2 unique values.\u001b[0m\n",
      "\u001b[34m#011Stage 2 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting FillNaFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 3 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting IdentityFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Stage 4 Generators:\u001b[0m\n",
      "\u001b[34m#011#011Fitting DropUniqueFeatureGenerator...\u001b[0m\n",
      "\u001b[34m#011Types of features in original data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('float', []) :  4 | ['Day Mins', 'Eve Mins', 'Night Mins', 'Intl Mins']\u001b[0m\n",
      "\u001b[34m#011#011('int', [])   : 95 | ['Account Length', 'VMail Message', 'Day Calls', 'Eve Calls', 'Night Calls', ...]\u001b[0m\n",
      "\u001b[34m#011Types of features in processed data (raw dtype, special dtypes):\u001b[0m\n",
      "\u001b[34m#011#011('float', [])     :  4 | ['Day Mins', 'Eve Mins', 'Night Mins', 'Intl Mins']\u001b[0m\n",
      "\u001b[34m#011#011('int', [])       :  7 | ['Account Length', 'VMail Message', 'Day Calls', 'Eve Calls', 'Night Calls', ...]\u001b[0m\n",
      "\u001b[34m#011#011('int', ['bool']) : 88 | ['State_AK', 'State_AL', 'State_AR', 'State_AZ', 'State_CA', ...]\u001b[0m\n",
      "\u001b[34m#0110.1s = Fit runtime\u001b[0m\n",
      "\u001b[34m#01199 features in original data used to generate 99 features in processed data.\u001b[0m\n",
      "\u001b[34m#011Train Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\u001b[0m\n",
      "\u001b[34mData preprocessing and feature engineering runtime = 0.13s ...\u001b[0m\n",
      "\u001b[34mAutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\u001b[0m\n",
      "\u001b[34m#011This metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\u001b[0m\n",
      "\u001b[34m#011To change this, specify the eval_metric argument of fit()\u001b[0m\n",
      "\u001b[34mFitting 13 L1 models ...\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsUnif_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.7709#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.1s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: KNeighborsDist_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.7791#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.1s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMXT_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9273#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0111.17s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBM_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9297#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.33s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestGini_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9334#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.7s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.11s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: RandomForestEntr_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9355#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.66s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.12s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: CatBoost_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9404#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.89s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesGini_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9216#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.67s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.12s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: ExtraTreesEntr_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9247#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.77s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.12s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetFastAI_BAG_L1 ...\u001b[0m\n",
      "\u001b[34mgenerated new fontManager\u001b[0m\n",
      "\u001b[34mNo improvement since epoch 2: early stopping\u001b[0m\n",
      "\u001b[34mNo improvement since epoch 2: early stopping\u001b[0m\n",
      "\u001b[34m#0110.8034#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0116.47s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.1s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: XGBoost_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9312#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.4s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.02s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: NeuralNetMXNet_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.9162#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0116.58s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.07s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: LightGBMLarge_BAG_L1 ...\u001b[0m\n",
      "\u001b[34m#0110.938#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0110.67s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.01s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mFitting model: WeightedEnsemble_L2 ...\u001b[0m\n",
      "\u001b[34m#0110.9474#011 = Validation score   (roc_auc)\u001b[0m\n",
      "\u001b[34m#0111.6s#011 = Training   runtime\u001b[0m\n",
      "\u001b[34m#0110.0s#011 = Validation runtime\u001b[0m\n",
      "\u001b[34mAutoGluon training complete, total runtime = 22.36s ...\u001b[0m\n",
      "\u001b[34mTabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/opt/ml/model/\")\u001b[0m\n",
      "\u001b[34mUsing validation_header.csv\u001b[0m\n",
      "\u001b[34mLoaded data from: /opt/ml/input/data/test/validation_header.csv | Columns = 100 / 100 | Rows = 1000 -> 1000\u001b[0m\n",
      "\u001b[34m                      model  score_test  score_val  pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\u001b[0m\n",
      "\u001b[34m0           CatBoost_BAG_L1    0.968310   0.940376        0.015566       0.014677  0.886339                 0.015566                0.014677           0.886339            1       True          7\u001b[0m\n",
      "\u001b[34m1       WeightedEnsemble_L2    0.966229   0.947371        0.640336       0.622511  6.688812                 0.004611                0.001395           1.603110            2       True         14\u001b[0m\n",
      "\u001b[34m2      LightGBMLarge_BAG_L1    0.963691   0.938023        0.015885       0.010091  0.666660                 0.015885                0.010091           0.666660            1       True         13\u001b[0m\n",
      "\u001b[34m3   RandomForestGini_BAG_L1    0.962877   0.933421        0.112377       0.112579  0.699357                 0.112377                0.112579           0.699357            1       True          5\u001b[0m\n",
      "\u001b[34m4   RandomForestEntr_BAG_L1    0.961554   0.935454        0.115260       0.121136  0.664288                 0.115260                0.121136           0.664288            1       True          6\u001b[0m\n",
      "\u001b[34m5           LightGBM_BAG_L1    0.959245   0.929716        0.011093       0.007519  0.327012                 0.011093                0.007519           0.327012            1       True          4\u001b[0m\n",
      "\u001b[34m6            XGBoost_BAG_L1    0.957560   0.931236        0.031993       0.019107  0.401591                 0.031993                0.019107           0.401591            1       True         11\u001b[0m\n",
      "\u001b[34m7         LightGBMXT_BAG_L1    0.954986   0.927299        0.015156       0.007953  1.167132                 0.015156                0.007953           1.167132            1       True          3\u001b[0m\n",
      "\u001b[34m8     NeuralNetMXNet_BAG_L1    0.954454   0.916158        0.266068       0.074241  6.577654                 0.266068                0.074241           6.577654            1       True         12\u001b[0m\n",
      "\u001b[34m9     ExtraTreesEntr_BAG_L1    0.943912   0.924730        0.113843       0.116916  0.768242                 0.113843                0.116916           0.768242            1       True          9\u001b[0m\n",
      "\u001b[34m10    ExtraTreesGini_BAG_L1    0.943005   0.921649        0.115190       0.117105  0.667093                 0.115190                0.117105           0.667093            1       True          8\u001b[0m\n",
      "\u001b[34m11   NeuralNetFastAI_BAG_L1    0.870621   0.803425        0.316933       0.101644  6.468362                 0.316933                0.101644           6.468362            1       True         10\u001b[0m\n",
      "\u001b[34m12    KNeighborsDist_BAG_L1    0.795380   0.779120        0.104516       0.101987  0.005122                 0.104516                0.101987           0.005122            1       True          2\u001b[0m\n",
      "\u001b[34m13    KNeighborsUnif_BAG_L1    0.789459   0.770924        0.104355       0.104491  0.006470                 0.104355                0.104491           0.006470            1       True          1\u001b[0m\n",
      "\u001b[34mComputing feature importance via permutation shuffling for 99 features using 1000 rows with 3 shuffle sets...\u001b[0m\n",
      "\u001b[34m#011205.99s#011= Expected runtime (68.66s per shuffle set)\u001b[0m\n",
      "\u001b[34m#01118.5s#011= Actual runtime (Completed 3 of 3 shuffle sets)\u001b[0m\n",
      "\u001b[34m2021-12-05 14:09:46,908 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2021-12-05 14:10:08 Uploading - Uploading generated training model\n",
      "2021-12-05 14:10:08 Completed - Training job completed\n",
      "Training seconds: 101\n",
      "Billable seconds: 101\n"
     ]
    }
   ],
   "source": [
    "job_name = utils.unique_name_from_base(\"test-autogluon-image\")\n",
    "ag.fit(\n",
    "    {\"config\": config_input, \"train\": train_input, \"test\": eval_input},\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6edb8e",
   "metadata": {},
   "source": [
    "### 모델 및 결과 추출\n",
    "\n",
    "AutoGluon models are portable: everything needed to deploy a trained model is in the tarball created by SageMaker.\n",
    "\n",
    "The artifact can be used locally, on EC2/ECS/EKS or served via SageMaker Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89ef503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {ag.model_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f120e3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 7521020 Dec  5 14:09 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -alF model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639e205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts_dir = ag.model_data.replace('model.tar.gz', '')\n",
    "output_dir = \"./train_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2fa856e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-322537213286/test-autogluon-image-1638713143-b199/output/output.tar.gz to train_output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!rm -rf {output_dir}\n",
    "!mkdir {output_dir}\n",
    "!aws s3 cp {artifacts_dir}output.tar.gz {output_dir}/output.tar.gz\n",
    "!tar -xzf {output_dir}/output.tar.gz -C {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f518a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.940376</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.014677</td>\n",
       "      <td>0.886339</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.014677</td>\n",
       "      <td>0.886339</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.966229</td>\n",
       "      <td>0.947371</td>\n",
       "      <td>0.640336</td>\n",
       "      <td>0.622511</td>\n",
       "      <td>6.688812</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>1.603110</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.963691</td>\n",
       "      <td>0.938023</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.666660</td>\n",
       "      <td>0.015885</td>\n",
       "      <td>0.010091</td>\n",
       "      <td>0.666660</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.962877</td>\n",
       "      <td>0.933421</td>\n",
       "      <td>0.112377</td>\n",
       "      <td>0.112579</td>\n",
       "      <td>0.699357</td>\n",
       "      <td>0.112377</td>\n",
       "      <td>0.112579</td>\n",
       "      <td>0.699357</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.961554</td>\n",
       "      <td>0.935454</td>\n",
       "      <td>0.115260</td>\n",
       "      <td>0.121136</td>\n",
       "      <td>0.664288</td>\n",
       "      <td>0.115260</td>\n",
       "      <td>0.121136</td>\n",
       "      <td>0.664288</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.959245</td>\n",
       "      <td>0.929716</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.327012</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.327012</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.957560</td>\n",
       "      <td>0.931236</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.401591</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.401591</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.954986</td>\n",
       "      <td>0.927299</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>1.167132</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NeuralNetMXNet_BAG_L1</td>\n",
       "      <td>0.954454</td>\n",
       "      <td>0.916158</td>\n",
       "      <td>0.266068</td>\n",
       "      <td>0.074241</td>\n",
       "      <td>6.577654</td>\n",
       "      <td>0.266068</td>\n",
       "      <td>0.074241</td>\n",
       "      <td>6.577654</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.943912</td>\n",
       "      <td>0.924730</td>\n",
       "      <td>0.113843</td>\n",
       "      <td>0.116916</td>\n",
       "      <td>0.768242</td>\n",
       "      <td>0.113843</td>\n",
       "      <td>0.116916</td>\n",
       "      <td>0.768242</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.943005</td>\n",
       "      <td>0.921649</td>\n",
       "      <td>0.115190</td>\n",
       "      <td>0.117105</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.115190</td>\n",
       "      <td>0.117105</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.870621</td>\n",
       "      <td>0.803425</td>\n",
       "      <td>0.316933</td>\n",
       "      <td>0.101644</td>\n",
       "      <td>6.468362</td>\n",
       "      <td>0.316933</td>\n",
       "      <td>0.101644</td>\n",
       "      <td>6.468362</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.795380</td>\n",
       "      <td>0.779120</td>\n",
       "      <td>0.104516</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.104516</td>\n",
       "      <td>0.101987</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.789459</td>\n",
       "      <td>0.770924</td>\n",
       "      <td>0.104355</td>\n",
       "      <td>0.104491</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.104355</td>\n",
       "      <td>0.104491</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                    model  score_test  score_val  \\\n",
       "0            0          CatBoost_BAG_L1    0.968310   0.940376   \n",
       "1            1      WeightedEnsemble_L2    0.966229   0.947371   \n",
       "2            2     LightGBMLarge_BAG_L1    0.963691   0.938023   \n",
       "3            3  RandomForestGini_BAG_L1    0.962877   0.933421   \n",
       "4            4  RandomForestEntr_BAG_L1    0.961554   0.935454   \n",
       "5            5          LightGBM_BAG_L1    0.959245   0.929716   \n",
       "6            6           XGBoost_BAG_L1    0.957560   0.931236   \n",
       "7            7        LightGBMXT_BAG_L1    0.954986   0.927299   \n",
       "8            8    NeuralNetMXNet_BAG_L1    0.954454   0.916158   \n",
       "9            9    ExtraTreesEntr_BAG_L1    0.943912   0.924730   \n",
       "10          10    ExtraTreesGini_BAG_L1    0.943005   0.921649   \n",
       "11          11   NeuralNetFastAI_BAG_L1    0.870621   0.803425   \n",
       "12          12    KNeighborsDist_BAG_L1    0.795380   0.779120   \n",
       "13          13    KNeighborsUnif_BAG_L1    0.789459   0.770924   \n",
       "\n",
       "    pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n",
       "0         0.015566       0.014677  0.886339                 0.015566   \n",
       "1         0.640336       0.622511  6.688812                 0.004611   \n",
       "2         0.015885       0.010091  0.666660                 0.015885   \n",
       "3         0.112377       0.112579  0.699357                 0.112377   \n",
       "4         0.115260       0.121136  0.664288                 0.115260   \n",
       "5         0.011093       0.007519  0.327012                 0.011093   \n",
       "6         0.031993       0.019107  0.401591                 0.031993   \n",
       "7         0.015156       0.007953  1.167132                 0.015156   \n",
       "8         0.266068       0.074241  6.577654                 0.266068   \n",
       "9         0.113843       0.116916  0.768242                 0.113843   \n",
       "10        0.115190       0.117105  0.667093                 0.115190   \n",
       "11        0.316933       0.101644  6.468362                 0.316933   \n",
       "12        0.104516       0.101987  0.005122                 0.104516   \n",
       "13        0.104355       0.104491  0.006470                 0.104355   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.014677           0.886339            1       True   \n",
       "1                 0.001395           1.603110            2       True   \n",
       "2                 0.010091           0.666660            1       True   \n",
       "3                 0.112579           0.699357            1       True   \n",
       "4                 0.121136           0.664288            1       True   \n",
       "5                 0.007519           0.327012            1       True   \n",
       "6                 0.019107           0.401591            1       True   \n",
       "7                 0.007953           1.167132            1       True   \n",
       "8                 0.074241           6.577654            1       True   \n",
       "9                 0.116916           0.768242            1       True   \n",
       "10                0.117105           0.667093            1       True   \n",
       "11                0.101644           6.468362            1       True   \n",
       "12                0.101987           0.005122            1       True   \n",
       "13                0.104491           0.006470            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           7  \n",
       "1          14  \n",
       "2          13  \n",
       "3           5  \n",
       "4           6  \n",
       "5           4  \n",
       "6          11  \n",
       "7           3  \n",
       "8          12  \n",
       "9           9  \n",
       "10          8  \n",
       "11         10  \n",
       "12          2  \n",
       "13          1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'{output_dir}/leaderboard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a9ac2",
   "metadata": {},
   "source": [
    "# Endpoint Deployment\n",
    "\n",
    "Upload the model we trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbc50996",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"sagemaker-autogluon-serving-trained-model\")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1341cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "# instance_type = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7839d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoGluonInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.3.1\",\n",
    "    instance_type=instance_type,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"tabular_serve.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a83c1e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(\n",
    "    initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed52079",
   "metadata": {},
   "source": [
    "### Predict on unlabeled test data\n",
    "\n",
    "Remove target variable (`class`) from the data and get predictions for a sample of 100 rows using the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c704f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3fc571",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test_data.drop(columns=\"Churn?_True.\")[:100].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bf995ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84b9f0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds   0.0  1.0\n",
       "actual          \n",
       "0.0      48    5\n",
       "1.0       3   44"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    index=test_data[\"Churn?_True.\"].astype(\"float\")[: len(preds)],\n",
    "    columns=pd.DataFrame(preds)[0],\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"preds\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b400a18",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a635d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd2aaf",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "\n",
    "Deploying a trained model to a hosted endpoint has been available in SageMaker since launch and is a great way to provide real-time predictions to a service like a website or mobile app. But, if the goal is to generate predictions from a trained model on a large dataset where minimizing latency isn’t a concern, then the batch transform functionality may be easier, more scalable, and more appropriate.\n",
    "\n",
    "[Read more about Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a44eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\n",
    "    \"sagemaker-autogluon-batch_transform-trained-model\"\n",
    ")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60b7f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d81646cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoGluonInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.3.1\",\n",
    "    instance_type=instance_type,\n",
    "    entry_point=\"tabular_serve-batch.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    predictor_cls=AutoGluonTabularPredictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c02f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=6,\n",
    "    max_concurrent_transforms=1,\n",
    "    output_path=output_path,\n",
    "    accept=\"application/json\",\n",
    "    assemble_with=\"Line\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befef33c",
   "metadata": {},
   "source": [
    "Prepare data for batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c3e0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[:100].to_csv(\"test_no_header.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde1cc7",
   "metadata": {},
   "source": [
    "Upload data to sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7215100",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = transformer.sagemaker_session.upload_data(\n",
    "    path=\"test_no_header.csv\", key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc0b832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\u001b[34mWarning: Calling MMS with mxnet-model-server. Please move to multi-model-server.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,706 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[34mMMS Home: /usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 8\u001b[0m\n",
      "\u001b[34mMax heap size: 6064 M\u001b[0m\n",
      "\u001b[34mPython executable: /usr/local/bin/python3.7\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[34mInitial Models: ALL\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 8\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPreload model: false\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,777 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,855 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_mxnet_serving_container.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 62\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.7.10\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,858 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,863 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,872 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,931 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,933 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,936 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,937 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,938 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,939 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,941 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,942 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,943 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,943 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,922 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000002-9d239cafa6f5a3f6-4a4bde39\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,925 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000007-b491dcafa6f5a3f6-e62dbc9e\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,928 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000003-efd85cafa6f5a3f6-cdbac655\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,931 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3914\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,931 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3894\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,935 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-8\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,935 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,945 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3940\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,945 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-6\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,953 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000006-b7dadcafa6f5a3f6-2715d91f\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,954 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3955\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,954 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-7\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,979 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000000-f1569cafa6f5a3f6-ebed3e3c\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,979 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000004-b34e5cafa6f5a3f6-135b9c29\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,979 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3980\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,980 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,980 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3965\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,980 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-5\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,002 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000001-1b2e9cafa6f5a3f6-517bfaf9\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,002 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3997\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,003 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,039 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000008-a199dcafa6f5a3f6-6ed73362\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,040 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4029\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,040 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:19,785 [INFO ] pool-1-thread-10 ACCESS_LOG - /169.254.255.130:37728 \"GET /ping HTTP/1.1\" 200 10\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:19,792 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:37732 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:19,837 [INFO ] W-model-8-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - buf : <_io.StringIO object at 0x7fd306d825f0>\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:21,610 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:21,610 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:37736 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[32m2021-12-05T14:18:19.797:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "\u001b[34mWarning: Calling MMS with mxnet-model-server. Please move to multi-model-server.\u001b[0m\n",
      "\u001b[35mWarning: Calling MMS with mxnet-model-server. Please move to multi-model-server.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,706 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[34mMMS Home: /usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 8\u001b[0m\n",
      "\u001b[34mMax heap size: 6064 M\u001b[0m\n",
      "\u001b[34mPython executable: /usr/local/bin/python3.7\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[34mInitial Models: ALL\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 8\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPreload model: false\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,777 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,855 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_mxnet_serving_container.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 62\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,706 [INFO ] main com.amazonaws.ml.mms.ModelServer - \u001b[0m\n",
      "\u001b[35mMMS Home: /usr/local/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 8\u001b[0m\n",
      "\u001b[35mMax heap size: 6064 M\u001b[0m\n",
      "\u001b[35mPython executable: /usr/local/bin/python3.7\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-mms.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/mms/models\u001b[0m\n",
      "\u001b[35mInitial Models: ALL\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 8\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPreload model: false\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,777 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-9000-model\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,855 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - model_service_worker started with args: --sock-type unix --sock-name /home/model-server/tmp/.mms.sock.9000 --handler sagemaker_mxnet_serving_container.handler_service --model-path /.sagemaker/mms/models/model --model-name model --preload-model false --tmp-dir /home/model-server/tmp\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - [PID] 62\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - MMS worker started.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.7.10\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,858 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,863 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,872 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,931 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,933 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,936 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,937 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,938 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,939 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,941 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,942 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,943 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:13,943 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,857 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Python runtime: 3.7.10\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,858 [INFO ] main com.amazonaws.ml.mms.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,863 [INFO ] main com.amazonaws.ml.mms.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,871 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,872 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.mms.sock.9000\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,931 [INFO ] main com.amazonaws.ml.mms.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,933 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,936 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,937 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,938 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,939 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,941 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,942 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,943 [WARN ] pool-2-thread-1 com.amazonaws.ml.mms.metrics.MetricCollector - worker pid is not available yet.\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:13,943 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.mms.sock.9000.\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,922 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000002-9d239cafa6f5a3f6-4a4bde39\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,922 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000002-9d239cafa6f5a3f6-4a4bde39\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,925 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000007-b491dcafa6f5a3f6-e62dbc9e\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,928 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000003-efd85cafa6f5a3f6-cdbac655\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,931 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3914\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,931 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3894\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,935 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-8\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,935 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,945 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3940\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,945 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-6\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,953 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000006-b7dadcafa6f5a3f6-2715d91f\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,954 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3955\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,954 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-7\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,979 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000000-f1569cafa6f5a3f6-ebed3e3c\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,979 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000004-b34e5cafa6f5a3f6-135b9c29\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,979 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3980\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,980 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,980 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3965\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:17,980 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-5\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,925 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000007-b491dcafa6f5a3f6-e62dbc9e\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,928 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000003-efd85cafa6f5a3f6-cdbac655\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,931 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3914\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,931 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3894\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,935 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-8\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,935 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-1\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,945 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3940\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,945 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-6\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,953 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000006-b7dadcafa6f5a3f6-2715d91f\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,954 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3955\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,954 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-7\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,979 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000000-f1569cafa6f5a3f6-ebed3e3c\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,979 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000004-b34e5cafa6f5a3f6-135b9c29\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,979 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3980\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,980 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-4\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,980 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3965\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:17,980 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-5\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,002 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000001-1b2e9cafa6f5a3f6-517bfaf9\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,002 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3997\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,003 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,039 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000008-a199dcafa6f5a3f6-6ed73362\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,040 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4029\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:18,040 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:18,002 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000001-1b2e9cafa6f5a3f6-517bfaf9\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:18,002 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 3997\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:18,003 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-3\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:18,039 [INFO ] W-9000-model-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - Model model loaded io_fd=0242a9fffefeff83-00000026-00000008-a199dcafa6f5a3f6-6ed73362\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:18,040 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 4029\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:18,040 [WARN ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerLifeCycle - attachIOStreams() threadName=W-model-2\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:19,785 [INFO ] pool-1-thread-10 ACCESS_LOG - /169.254.255.130:37728 \"GET /ping HTTP/1.1\" 200 10\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:19,792 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:37732 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:19,837 [INFO ] W-model-8-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - buf : <_io.StringIO object at 0x7fd306d825f0>\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:19,785 [INFO ] pool-1-thread-10 ACCESS_LOG - /169.254.255.130:37728 \"GET /ping HTTP/1.1\" 200 10\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:19,792 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:37732 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:19,837 [INFO ] W-model-8-stdout com.amazonaws.ml.mms.wlm.WorkerLifeCycle - buf : <_io.StringIO object at 0x7fd306d825f0>\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:21,610 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[34m2021-12-05 14:18:21,610 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:37736 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:21,610 [INFO ] W-9000-model com.amazonaws.ml.mms.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[35m2021-12-05 14:18:21,610 [INFO ] W-9000-model ACCESS_LOG - /169.254.255.130:37736 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[32m2021-12-05T14:18:19.797:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    test_input,\n",
    "    input_filter=\"$[1:]\",  # filter-out target variable\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "#     output_filter=\"$[0]\",  # keep only prediction class in the output\n",
    ")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a1078f",
   "metadata": {},
   "source": [
    "Download batch transform outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10e62cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-322537213286/autogluon_sm/2021-12-05-14-05-42-648/output/test_no_header.csv.out to ./test_no_header.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {transformer.output_path[:-1]}/test_no_header.csv.out ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a84633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_json(\"test_no_header.csv.out\", orient=\"index\").sort_index()[1:].T\n",
    "result.columns = [\"preds\", \"actual\"]\n",
    "result['preds'] = result['preds'].apply(lambda x: 1.0 if x>=0.5 else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "008a6078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>preds</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "preds   0.0  1.0\n",
       "actual          \n",
       "0.0      51    0\n",
       "1.0       0   49"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    index=result[\"actual\"],\n",
    "    columns=result[\"preds\"],\n",
    "    rownames=[\"actual\"],\n",
    "    colnames=[\"preds\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9106308",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial we successfully trained an AutoGluon model and explored a few options how to deploy it using SageMaker. Any of the sections of this tutorial (training/endpoint inference/batch inference) can be used independently (i.e. train locally, deploy to SageMaker, or vice versa).\n",
    "\n",
    "Next steps:\n",
    "* [Learn more](https://auto.gluon.ai) about AutoGluon, explore [tutorials](https://auto.gluon.ai/stable/tutorials/index.html).\n",
    "* Explore [SageMaker inference documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.",
  "papermill": {
   "default_parameters": {},
   "duration": 311.728138,
   "end_time": "2021-06-07T00:14:55.273560",
   "environment_variables": {},
   "exception": true,
   "input_path": "xgboost_customer_churn.ipynb",
   "output_path": "/opt/ml/processing/output/xgboost_customer_churn-2021-06-07-00-06-03.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-06-07T00:09:43.545422",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
